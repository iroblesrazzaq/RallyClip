{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from lstm_model_arch import TennisPointLSTM\n",
    "import scipy.ndimage\n",
    "from typing import Optional\n",
    "\n",
    "\"\"\"\n",
    "My test.py file is my current evaluation file. however, it just looks at sequences, not the whole video. \n",
    "I need to further establish my post processing pipeline. The final output of my pipeline should be \n",
    "a csv of start_time, end_times, which i can compare to the annotated targets. \n",
    "For now, we will use the same gaussian smoothing and hysteresis filtering that we're using in the test.py file. \n",
    "\n",
    "Your task is to write a new file that runs the inference on an entire video's sequence file\n",
    "\"\"\"\n",
    "\n",
    "GAUSSIAN_SIGMA = 1.5  # for smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b6729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(\n",
    "    checkpoint_path: str,\n",
    "    input_size: int = 360,\n",
    "    hidden_size: int = 128,\n",
    "    num_layers: int = 2,\n",
    "    bidirectional: bool = True,\n",
    "    return_logits: bool = False,\n",
    "):\n",
    "    \"\"\"Load model weights from checkpoint, adapting architecture if needed.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # Extract model state dict\n",
    "    if isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n",
    "        state_dict = ckpt['model_state_dict']\n",
    "    elif isinstance(ckpt, dict) and any(k.startswith('lstm.') or k.startswith('fc.') for k in ckpt.keys()):\n",
    "        state_dict = ckpt\n",
    "    else:\n",
    "        # Fallback: attempt to use as state_dict\n",
    "        state_dict = ckpt\n",
    "\n",
    "    # Infer architecture from weights if possible\n",
    "    inferred_input_size = input_size\n",
    "    inferred_hidden_size = hidden_size\n",
    "    inferred_num_layers = num_layers\n",
    "    inferred_bidirectional = bidirectional\n",
    "\n",
    "    try:\n",
    "        # weight_ih_l0 shape: (4*hidden_size, input_size)\n",
    "        w_ih_l0 = state_dict.get('lstm.weight_ih_l0', None)\n",
    "        if w_ih_l0 is not None:\n",
    "            inferred_hidden_size = w_ih_l0.shape[0] // 4\n",
    "            inferred_input_size = w_ih_l0.shape[1]\n",
    "\n",
    "        # Determine num_layers by counting layers\n",
    "        layer_indices = set()\n",
    "        for k in state_dict.keys():\n",
    "            if k.startswith('lstm.weight_ih_l'):\n",
    "                try:\n",
    "                    idx_str = k.split('lstm.weight_ih_l')[1]\n",
    "                    idx = int(idx_str.split('_')[0]) if '_' in idx_str else int(idx_str)\n",
    "                    layer_indices.add(idx)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if layer_indices:\n",
    "            inferred_num_layers = max(layer_indices) + 1\n",
    "\n",
    "        # Bidirectionality: presence of any reverse weights\n",
    "        inferred_bidirectional = any('_reverse' in k for k in state_dict.keys())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Build model with inferred architecture\n",
    "    model = TennisPointLSTM(\n",
    "        input_size=inferred_input_size,\n",
    "        hidden_size=inferred_hidden_size,\n",
    "        num_layers=inferred_num_layers,\n",
    "        dropout=0.2,\n",
    "        bidirectional=inferred_bidirectional,\n",
    "        return_logits=return_logits,\n",
    "    )\n",
    "\n",
    "    # Load strictly now that shapes should match\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\n",
    "        f\"Loaded checkpoint: {checkpoint_path} \"\n",
    "        f\"(input_size={inferred_input_size}, hidden_size={inferred_hidden_size}, \"\n",
    "        f\"num_layers={inferred_num_layers}, bidirectional={inferred_bidirectional})\"\n",
    "    )\n",
    "    return model, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d01415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: checkpoints/seq_len150/best_model.pth (input_size=360, hidden_size=128, num_layers=2, bidirectional=True)\n"
     ]
    }
   ],
   "source": [
    "model_path = 'checkpoints/seq_len150/best_model.pth'\n",
    "model, device = load_model_from_checkpoint(model_path, bidirectional=True, return_logits=False)\n",
    "\n",
    "\n",
    "\n",
    "# load whole feature npz file for a specific video\n",
    "video_feature_path = 'pose_data/features/yolos_0.25conf_15fps_0s_to_99999s/Aditi Narayan ï½œ Matchplay_features.npz'\n",
    "data = np.load(video_feature_path)\n",
    "targets = data['targets']\n",
    "# create our ordered list of sequences with 50% overlap: must carefully track frame numbers\n",
    "\n",
    "num_frames = len(data['features'])\n",
    "sequence_length = 150 \n",
    "overlap = 75\n",
    "if num_frames < sequence_length:\n",
    "    raise ValueError(\"input video too short\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "404d649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 232 sequences for 17439 frames\n",
      "Coverage: 0 to 17439\n",
      "Start indices: [0, 75, 150, 225, 300]...[17025, 17100, 17175, 17250, 17289]\n",
      "WARNING: Excessive overlap of 111 frames between sequences 230 and 231\n"
     ]
    }
   ],
   "source": [
    "# Generate sequence start indices with 50% overlap (150 frame steps)\n",
    "# Ensure we cover all frames without gaps\n",
    "start_idxs = []\n",
    "idx = 0\n",
    "while idx + sequence_length <= num_frames:\n",
    "    start_idxs.append(idx)\n",
    "    idx += overlap\n",
    "\n",
    "# If the last sequence doesn't reach the end, add one more sequence\n",
    "if start_idxs[-1] + sequence_length < num_frames:\n",
    "    start_idxs.append(num_frames - sequence_length)\n",
    "\n",
    "print(f\"Generated {len(start_idxs)} sequences for {num_frames} frames\")\n",
    "print(f\"Coverage: {start_idxs[0]} to {start_idxs[-1] + sequence_length}\")\n",
    "print(f\"Start indices: {start_idxs[:5]}...{start_idxs[-5:] if len(start_idxs) > 5 else start_idxs}\")\n",
    "\n",
    "# Check for gaps\n",
    "for i in range(len(start_idxs) - 1):\n",
    "    gap = start_idxs[i+1] - (start_idxs[i] + sequence_length)\n",
    "    if gap > 0:\n",
    "        print(f\"WARNING: Gap of {gap} frames between sequences {i} and {i+1}\")\n",
    "    elif gap < -overlap:\n",
    "        print(f\"WARNING: Excessive overlap of {-gap} frames between sequences {i} and {i+1}\")\n",
    "\n",
    "ordered_sequences = []\n",
    "output_arr = np.full((3, num_frames), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d72e35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on 232 sequences...\n",
      "  Seq 0: frames 0-149 -> row 0\n",
      "  Seq 1: frames 75-224 -> row 1\n",
      "  Seq 2: frames 150-299 -> row 0\n",
      "  Seq 3: frames 225-374 -> row 1\n",
      "  Seq 4: frames 300-449 -> row 0\n",
      "  Seq 227: frames 17025-17174 -> row 1\n",
      "  Seq 228: frames 17100-17249 -> row 0\n",
      "  Seq 229: frames 17175-17324 -> row 1\n",
      "  Seq 230: frames 17250-17399 -> row 0\n",
      "  Seq 231: frames 17289-17438 -> row 2\n",
      "Checking output_arr coverage...\n",
      "  Row 0: 39/17439 NaNs (0.2%)\n",
      "  Row 1: 189/17439 NaNs (1.1%)\n",
      "  Row 2: 17289/17439 NaNs (99.1%)\n",
      "avg_probs: 0/17439 NaNs (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# now we construct the feature lists, perform inference, and fill output array, tracking start indexes\n",
    "print(f\"Running inference on {len(start_idxs)} sequences...\")\n",
    "for seq_idx, i in enumerate(start_idxs):\n",
    "    # slice features and convert to tensor of shape (1, sequence_length, input_size)\n",
    "    seq_np = data['features'][i:i+sequence_length, :].astype(np.float32)\n",
    "    seq_tensor = torch.from_numpy(seq_np).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(seq_tensor)  # (1, seq_len, 1)\n",
    "    output_sequence = output_tensor.squeeze().detach().cpu().numpy()  # (seq_len,)\n",
    "    \n",
    "    # Find which row to place this sequence in\n",
    "    placed = False\n",
    "    for row in range(3):\n",
    "        if np.isnan(output_arr[row, i:i+sequence_length]).all():\n",
    "            output_arr[row, i:i+sequence_length] = output_sequence\n",
    "            if seq_idx < 5 or seq_idx >= len(start_idxs) - 5:  # Debug first/last few\n",
    "                print(f\"  Seq {seq_idx}: frames {i}-{i+sequence_length-1} -> row {row}\")\n",
    "            placed = True\n",
    "            break\n",
    "    \n",
    "    if not placed:\n",
    "        print(f\"ERROR: Could not place sequence {seq_idx} (frames {i}-{i+sequence_length-1})\")\n",
    "        raise ValueError('res arr filling logic messed up')\n",
    "\n",
    "# now we have filled res_arr. next, get 1, num_frames array by averaging over 0th axis, and apply gaussian smoothing\n",
    "print(\"Checking output_arr coverage...\")\n",
    "for row in range(3):\n",
    "    nan_count = np.isnan(output_arr[row, :]).sum()\n",
    "    print(f\"  Row {row}: {nan_count}/{num_frames} NaNs ({100*nan_count/num_frames:.1f}%)\")\n",
    "\n",
    "avg_probs = np.nanmean(output_arr, axis=0)\n",
    "nan_count_avg = np.isnan(avg_probs).sum()\n",
    "print(f\"avg_probs: {nan_count_avg}/{num_frames} NaNs ({100*nan_count_avg/num_frames:.1f}%)\")\n",
    "\n",
    "if nan_count_avg > 0:\n",
    "    # Find NaN ranges\n",
    "    nan_mask = np.isnan(avg_probs)\n",
    "    nan_starts = np.where(np.diff(np.concatenate(([False], nan_mask))))[0]\n",
    "    nan_ends = np.where(np.diff(np.concatenate((nan_mask, [False]))))[0]\n",
    "    print(\"NaN ranges:\")\n",
    "    for start, end in zip(nan_starts, nan_ends):\n",
    "        print(f\"  frames {start}-{end-1} ({end-start} frames)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23aad28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7253856299099719)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple = (avg_probs >= 0.5).astype(int)\n",
    "np.sum(simple == targets)/len(avg_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d02f795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac3058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_probs head: [0.25714421 0.24497803 0.24257775 0.23969215 0.23660417 0.23375887\n",
      " 0.23123586 0.22903688 0.22754726 0.22592807 0.22493242 0.22408922\n",
      " 0.2234481  0.22302155 0.2226958  0.22251448 0.22248556 0.22246866\n",
      " 0.22262025 0.22260508 0.22263879 0.22263867 0.22269064 0.22282159\n",
      " 0.22285062 0.22299479 0.22307621 0.22311153 0.22327054 0.22334903]\n",
      "smoothed_probs head: [0.25013953 0.24738353 0.24353737 0.23994568 0.23684816 0.23409574\n",
      " 0.23164853 0.2295414  0.22778259 0.22634749 0.22520576 0.22432293\n",
      " 0.22365868 0.22317642 0.22284788 0.22265036 0.22255994 0.22254567\n",
      " 0.22257072 0.2226044  0.22263642 0.22267479 0.22272979 0.22280224\n",
      " 0.22288595 0.2229744  0.22306432 0.22315988 0.2232749  0.22343719]\n",
      "smoothed stats: min= 0.002126772655174136 max= 0.8780487775802612 nans= 0\n",
      "Accuracy: 0.706, High: 0.5, Low: 0.1 \n",
      "Accuracy: 0.717, High: 0.5, Low: 0.15 \n",
      "Accuracy: 0.718, High: 0.5, Low: 0.2 \n",
      "Accuracy: 0.718, High: 0.5, Low: 0.25 \n",
      "Accuracy: 0.719, High: 0.5, Low: 0.3 \n",
      "Accuracy: 0.724, High: 0.5, Low: 0.35 \n",
      "Accuracy: 0.725, High: 0.5, Low: 0.4 \n",
      "Accuracy: 0.725, High: 0.5, Low: 0.45 \n",
      "Accuracy: 0.712, High: 0.55, Low: 0.1 \n",
      "Accuracy: 0.721, High: 0.55, Low: 0.15 \n",
      "Accuracy: 0.722, High: 0.55, Low: 0.2 \n",
      "Accuracy: 0.722, High: 0.55, Low: 0.25 \n",
      "Accuracy: 0.723, High: 0.55, Low: 0.3 \n",
      "Accuracy: 0.727, High: 0.55, Low: 0.35 \n",
      "Accuracy: 0.728, High: 0.55, Low: 0.4 \n",
      "Accuracy: 0.728, High: 0.55, Low: 0.45 \n",
      "Accuracy: 0.713, High: 0.6, Low: 0.1 \n",
      "Accuracy: 0.722, High: 0.6, Low: 0.15 \n",
      "Accuracy: 0.723, High: 0.6, Low: 0.2 \n",
      "Accuracy: 0.723, High: 0.6, Low: 0.25 \n",
      "Accuracy: 0.724, High: 0.6, Low: 0.3 \n",
      "Accuracy: 0.728, High: 0.6, Low: 0.35 \n",
      "Accuracy: 0.729, High: 0.6, Low: 0.4 \n",
      "Accuracy: 0.729, High: 0.6, Low: 0.45 \n",
      "Accuracy: 0.717, High: 0.65, Low: 0.1 \n",
      "Accuracy: 0.725, High: 0.65, Low: 0.15 \n",
      "Accuracy: 0.726, High: 0.65, Low: 0.2 \n",
      "Accuracy: 0.726, High: 0.65, Low: 0.25 \n",
      "Accuracy: 0.727, High: 0.65, Low: 0.3 \n",
      "Accuracy: 0.731, High: 0.65, Low: 0.35 \n",
      "Accuracy: 0.731, High: 0.65, Low: 0.4 \n",
      "Accuracy: 0.731, High: 0.65, Low: 0.45 \n",
      "Accuracy: 0.719, High: 0.7, Low: 0.1 \n",
      "Accuracy: 0.726, High: 0.7, Low: 0.15 \n",
      "Accuracy: 0.727, High: 0.7, Low: 0.2 \n",
      "Accuracy: 0.727, High: 0.7, Low: 0.25 \n",
      "Accuracy: 0.728, High: 0.7, Low: 0.3 \n",
      "Accuracy: 0.732, High: 0.7, Low: 0.35 \n",
      "Accuracy: 0.733, High: 0.7, Low: 0.4 \n",
      "Accuracy: 0.733, High: 0.7, Low: 0.45 \n",
      "Accuracy: 0.732, High: 0.75, Low: 0.1 \n",
      "Accuracy: 0.732, High: 0.75, Low: 0.15 \n",
      "Accuracy: 0.732, High: 0.75, Low: 0.2 \n",
      "Accuracy: 0.733, High: 0.75, Low: 0.25 \n",
      "Accuracy: 0.733, High: 0.75, Low: 0.3 \n",
      "Accuracy: 0.735, High: 0.75, Low: 0.35 \n",
      "Accuracy: 0.735, High: 0.75, Low: 0.4 \n",
      "Accuracy: 0.735, High: 0.75, Low: 0.45 \n",
      "Accuracy: 0.732, High: 0.8, Low: 0.1 \n",
      "Accuracy: 0.733, High: 0.8, Low: 0.15 \n",
      "Accuracy: 0.733, High: 0.8, Low: 0.2 \n",
      "Accuracy: 0.733, High: 0.8, Low: 0.25 \n",
      "Accuracy: 0.733, High: 0.8, Low: 0.3 \n",
      "Accuracy: 0.735, High: 0.8, Low: 0.35 \n",
      "Accuracy: 0.735, High: 0.8, Low: 0.4 \n",
      "Accuracy: 0.735, High: 0.8, Low: 0.45 \n",
      "Accuracy: 0.733, High: 0.85, Low: 0.1 \n",
      "Accuracy: 0.733, High: 0.85, Low: 0.15 \n",
      "Accuracy: 0.733, High: 0.85, Low: 0.2 \n",
      "Accuracy: 0.733, High: 0.85, Low: 0.25 \n",
      "Accuracy: 0.734, High: 0.85, Low: 0.3 \n",
      "Accuracy: 0.735, High: 0.85, Low: 0.35 \n",
      "Accuracy: 0.736, High: 0.85, Low: 0.4 \n",
      "Accuracy: 0.736, High: 0.85, Low: 0.45 \n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Require 0 <= low < high <= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     84\u001b[39m HIGH_THRESHOLD = \u001b[32m60\u001b[39m  \u001b[38;5;66;03m# for starting a point\u001b[39;00m\n\u001b[32m     85\u001b[39m LOW_THRESHOLD =   \u001b[32m40\u001b[39m \u001b[38;5;66;03m# for ending a point\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m filtered_sequence = \u001b[43mhysteresis_threshold\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmoothed_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLOW_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHIGH_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_duration\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m accuracy = np.sum(filtered_sequence == targets) / num_frames\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, High: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHIGH_THRESHOLD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Low: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOW_THRESHOLD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mhysteresis_threshold\u001b[39m\u001b[34m(values, low, high, min_duration)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhysteresis_threshold\u001b[39m(\n\u001b[32m     30\u001b[39m     values: np.ndarray,\n\u001b[32m     31\u001b[39m     low: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.3\u001b[39m,\n\u001b[32m     32\u001b[39m     high: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.7\u001b[39m,\n\u001b[32m     33\u001b[39m     min_duration: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m     34\u001b[39m ) -> np.ndarray:\n\u001b[32m     35\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply 1D hysteresis thresholding to a probability-like signal.\u001b[39;00m\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[33;03m    - Enter active state when values >= high\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \u001b[33;03m    Returns a 0/1 array of the same length.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m0.0\u001b[39m <= low < high <= \u001b[32m1.0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mRequire 0 <= low < high <= 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(values)\n\u001b[32m     44\u001b[39m     pred = np.zeros(n, dtype=np.int8)\n",
      "\u001b[31mAssertionError\u001b[39m: Require 0 <= low < high <= 1"
     ]
    }
   ],
   "source": [
    "smoothed_probs = scipy.ndimage.gaussian_filter1d(avg_probs.astype(np.float32), sigma=GAUSSIAN_SIGMA)\n",
    "_ = smoothed_probs  # silence variable display in notebooks\n",
    "\n",
    "# perform hysteresis filtering on smoothed sequence\n",
    "\n",
    "# use hysteresis for start/end times, write to csv\n",
    "\n",
    "# %%%\n",
    "smoothed_probs.shape\n",
    "# %%\n",
    "\n",
    "print(\"avg_probs head:\", avg_probs[:30])\n",
    "print(\"smoothed_probs head:\", smoothed_probs[:30])\n",
    "print(\n",
    "    \"smoothed stats:\",\n",
    "    \"min=\", float(np.nanmin(smoothed_probs)),\n",
    "    \"max=\", float(np.nanmax(smoothed_probs)),\n",
    "    \"nans=\", int(np.isnan(smoothed_probs).sum()),\n",
    ")\n",
    "# %%\n",
    "# now run hysteresis filtering to get actual discrete in vs out of point vals? \n",
    "# or something to get discrete in vs out of points\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n",
    "def hysteresis_threshold(\n",
    "    values: np.ndarray,\n",
    "    low: float = 0.3,\n",
    "    high: float = 0.7,\n",
    "    min_duration: int = 0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Apply 1D hysteresis thresholding to a probability-like signal.\n",
    "\n",
    "    - Enter active state when values >= high\n",
    "    - Exit active state when values < low\n",
    "    - Optional min_duration suppresses short active segments\n",
    "    Returns a 0/1 array of the same length.\n",
    "    \"\"\"\n",
    "    assert 0.0 <= low < high <= 1.0, \"Require 0 <= low < high <= 1\"\n",
    "    n = len(values)\n",
    "    pred = np.zeros(n, dtype=np.int8)\n",
    "    active = False\n",
    "    start_idx: Optional[int] = None\n",
    "\n",
    "    for i in range(n):\n",
    "        v = values[i]\n",
    "        if not active:\n",
    "            if v >= high:\n",
    "                active = True\n",
    "                start_idx = i\n",
    "        else:\n",
    "            if v < low:\n",
    "                end_idx = i\n",
    "                if start_idx is not None and (end_idx - start_idx) >= max(0, min_duration):\n",
    "                    pred[start_idx:end_idx] = 1\n",
    "                active = False\n",
    "                start_idx = None\n",
    "\n",
    "    # Handle active segment reaching the end\n",
    "    if active and start_idx is not None:\n",
    "        end_idx = n\n",
    "        if (end_idx - start_idx) >= max(0, min_duration):\n",
    "            pred[start_idx:end_idx] = 1\n",
    "\n",
    "    return pred.astype(np.int32)\n",
    "\n",
    "# %%\n",
    "for high_thresh in range(50, 90, 5):\n",
    "    for low_thresh in range(10, 50, 5):\n",
    "        # now we compare output!\n",
    "        HIGH_THRESHOLD = high_thresh/100  # for starting a point\n",
    "        LOW_THRESHOLD =   low_thresh / 100 # for ending a point\n",
    "\n",
    "\n",
    "        filtered_sequence = hysteresis_threshold(smoothed_probs, LOW_THRESHOLD, HIGH_THRESHOLD, min_duration=6)\n",
    "        accuracy = np.sum(filtered_sequence == targets) / num_frames\n",
    "        print(f\"Accuracy: {accuracy:.3f}, High: {HIGH_THRESHOLD}, Low: {LOW_THRESHOLD} \")\n",
    "\n",
    "\n",
    "# %%\n",
    "HIGH_THRESHOLD = 60  # for starting a point\n",
    "LOW_THRESHOLD =   40 # for ending a point\n",
    "\n",
    "\n",
    "filtered_sequence = hysteresis_threshold(smoothed_probs, LOW_THRESHOLD, HIGH_THRESHOLD, min_duration=6)\n",
    "accuracy = np.sum(filtered_sequence == targets) / num_frames\n",
    "print(f\"Accuracy: {accuracy:.3f}, High: {HIGH_THRESHOLD}, Low: {LOW_THRESHOLD} \")\n",
    "\n",
    "np.unique(filtered_sequence)\n",
    "\n",
    "# %% next, based on point vs not in point, we create final start_time,end_time times\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tennis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
